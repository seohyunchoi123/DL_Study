{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = 'Hi! My name is Seohyun Choi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_to_idx = {ch : idx for idx, ch in enumerate(list(set(sentence)))}\n",
    "idx_to_ch = {idx : ch for idx, ch in enumerate(list(set(sentence)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_nodes = 50\n",
    "n_characters= len(ch_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [],
   "source": [
    "whh = tf.Variable(tf.random_normal(shape=[n_nodes, n_nodes], dtype=tf.float32))\n",
    "wxh = tf.Variable(tf.random_normal(shape=[ n_characters, n_nodes], dtype=tf.float32))\n",
    "why = tf.Variable(tf.random_normal(shape=[ n_nodes,  n_characters], dtype=tf.float32))\n",
    "bh = tf.Variable(tf.random_normal(shape=[n_nodes], dtype=tf.float32))\n",
    "by = tf.Variable(tf.random_normal(shape=[n_characters], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = tf.placeholder(shape=[None, n_characters], dtype=tf.float32)\n",
    "train_y = tf.placeholder(shape=[None ,n_characters], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making each softmax at every hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "hidden_layer = {}\n",
    "output ={}\n",
    "pred={}\n",
    "loss={}\n",
    "training={}\n",
    "for i in range(len(sentence)):\n",
    "    if i!=0:\n",
    "        hidden_layer[i] = tf.add(tf.matmul(train_x, wxh), tf.matmul(hidden_layer[i-1], whh))\n",
    "    else :\n",
    "        hidden_layer[i] = tf.matmul(train_x, wxh)\n",
    "    hidden_layer[i]= tf.add(hidden_layer[i], bh)\n",
    "    hidden_layer[i] = tf.tanh(hidden_layer[i])\n",
    "    output[i] = tf.add(tf.matmul(hidden_layer[i], why), by)  \n",
    "    pred[i] = tf.nn.softmax(output[i])\n",
    "    loss[i] = tf.reduce_mean(tf.reduce_sum(train_y * -tf.log(pred[i])))\n",
    "    training[i] = opt.minimize(loss[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def one_hot(x, depth):\n",
    "    result = []\n",
    "    for num in x:\n",
    "        t = np.zeros(depth)\n",
    "        t[num]=1\n",
    "        result.append(t)\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = sentence[:-1]\n",
    "Y = sentence[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx =[]\n",
    "for ch in x:\n",
    "    idx = ch_to_idx[ch]\n",
    "    xx.append(idx)\n",
    "xx = one_hot(xx, depth = n_characters)\n",
    "\n",
    "yy =[]\n",
    "for ch in Y:\n",
    "    idx = ch_to_idx[ch]\n",
    "    yy.append(idx)\n",
    "yy = one_hot(yy, depth = n_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334.1987777352333\n",
      "72.48257341980934\n",
      "46.89181727170944\n",
      "53.41988143324852\n",
      "170.44070886130794\n",
      "108.3908291310072\n",
      "61.093458987772465\n",
      "137.52346435002983\n",
      "60.64919745665975\n",
      "76.7251137830317\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for _ in range(20000):\n",
    "    for i in range(len(sentence)-1):\n",
    "        sess.run(training[i], feed_dict={train_x : np.reshape(xx[i], newshape=[1,n_characters]), \n",
    "                                      train_y : np.reshape(yy[i], newshape=[1,n_characters])})\n",
    "    if _ % 2000 ==0: print(sum(sess.run(loss,feed_dict={train_x : np.reshape(xx[i], newshape=[1,n_characters]), \n",
    "                                                     train_y : np.reshape(yy[i], newshape=[1,n_characters])}).values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! My name is Seohyun Choi"
     ]
    }
   ],
   "source": [
    "# model test\n",
    "test_x = xx\n",
    "print('H', end='')\n",
    "for i in range(len(sentence)-1):\n",
    "    t = sess.run(pred[i], feed_dict={train_x: np.reshape(test_x[i], newshape=[1,n_characters])})\n",
    "    tt = np.argmax(t)\n",
    "    result = idx_to_ch[tt]\n",
    "    print(result, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making one combined softmax for all hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hidden_layer = {}\n",
    "pred =[]\n",
    "for i in range(len(sentence)-1):\n",
    "    if i!=0:\n",
    "        hidden_layer[i] = tf.add(tf.matmul(tf.reshape(train_x[i], [1,n_characters]), wxh), tf.matmul(hidden_layer[i-1], whh))\n",
    "    else :\n",
    "        hidden_layer[i] = tf.matmul(tf.reshape(train_x[i], [1,n_characters]), wxh)\n",
    "    hidden_layer[i]= tf.add(hidden_layer[i], bh)\n",
    "    hidden_layer[i] = tf.tanh(hidden_layer[i])\n",
    "    output = tf.add(tf.matmul(hidden_layer[i], why), by)\n",
    "    pred.append(tf.nn.softmax(output)) # 밑에처럼하나 똑같네 \n",
    "#pred = tf.nn.softmax(output)\n",
    "log_pred = tf.reshape(tf.log(pred), [-1,n_characters])\n",
    "loss = tf.reduce_mean(tf.reduce_sum(train_y * -log_pred))\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "training = opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def one_hot(x, depth):\n",
    "    result = []\n",
    "    for num in x:\n",
    "        t = np.zeros(depth)\n",
    "        t[num]=1\n",
    "        result.append(t)\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = sentence[:-1]\n",
    "Y = sentence[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xx =[]\n",
    "for ch in x:\n",
    "    idx = ch_to_idx[ch]\n",
    "    xx.append(idx)\n",
    "xx = one_hot(xx, depth = n_characters)\n",
    "\n",
    "yy =[]\n",
    "for ch in Y:\n",
    "    idx = ch_to_idx[ch]\n",
    "    yy.append(idx)\n",
    "yy = one_hot(yy, depth = n_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316.18646\n",
      "4.4459343\n",
      "0.48795283\n",
      "0.1912252\n",
      "0.09577693\n",
      "0.053253867\n",
      "0.031076472\n",
      "0.01856732\n",
      "0.011221308\n",
      "0.0068155187\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for iteration in range(10000):\n",
    "    sess.run(training, feed_dict={train_x : xx, train_y : yy})\n",
    "    if iteration % 1000 ==0: print(sess.run(loss, feed_dict={train_x : xx, train_y : yy}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! My name is Seohyun Choi"
     ]
    }
   ],
   "source": [
    "# model test\n",
    "test_x = xx\n",
    "print('H', end='')\n",
    "preds = sess.run(pred, feed_dict={train_x: test_x})\n",
    "for t in preds:\n",
    "    tt = np.argmax(t)\n",
    "    result = idx_to_ch[tt]\n",
    "    print(result, end='')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
