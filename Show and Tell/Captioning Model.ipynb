{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\CSH\\\\Desktop\\\\투빅스 프로젝트 2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_dir = 'C:\\\\Users\\\\CSH\\\\Desktop\\\\투빅스 프로젝트 2/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CSH\\Desktop\\투빅스 프로젝트 2/train/\n",
      "[]\n",
      "['000000000139.jpg', '000000000285.jpg', '000000000632.jpg', '000000000724.jpg', '000000000776.jpg', '000000000785.jpg', '000000000802.jpg', '000000000872.jpg', '000000000885.jpg', '000000001000.jpg']\n"
     ]
    }
   ],
   "source": [
    "for path, dir, files in os.walk(image_dir):\n",
    "    print(path)\n",
    "    print(dir)\n",
    "    print(files) # 이렇게다 파일들로 들어가서 그안의 목록들까지 보는구나 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = []\n",
    "resizing = (32, 32)\n",
    "\n",
    "for path, dir, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        image_dir = path + '/' + file \n",
    "        img = Image.open(image_dir)\n",
    "        img = img.resize(resizing)\n",
    "        if not img.format == \"RGB\": # 이미지의 포맷이 RGB가 아닐 경우, RGB로 convert 시킴\n",
    "            img = img.convert(\"RGB\")\n",
    "        train_x.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = train_x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = ['A woman is talking to an old lady outside through window.',\n",
    "          'A bear is looking somewhere on the grass.',\n",
    "          'A room with blue bed and full shelf of books and dressing table.',\n",
    "          'A stop sign on street is turned over',\n",
    "          'Three bear dolls are aligned',\n",
    "          'A woman in red ski jacket is skiing.',\n",
    "          'A kitchen with white oven and white fridge.',\n",
    "          'Two men are playing basket ball.',\n",
    "          'A mann is playing tennis in a match.',\n",
    "          'A group of people are standing on batminton court.',\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_sen = []\n",
    "y_sen = []\n",
    "seq_len =[]\n",
    "max_len = 0\n",
    "for sentence in sentences:\n",
    "    t = sentence.split(' ')\n",
    "    max_len = max(max_len, len(t))\n",
    "    x_sen.append(t) # 나중에 x_sen에는 image 값 벡터가 하나 더 붙을꺼다. \n",
    "    y_sen.append(t)\n",
    "    seq_len.append(len(t)+2) # x_image,start, end tocken까지 고려해서 ! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 10, 15, 10, 7, 10, 10, 8, 10, 11]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=[]\n",
    "b=[]\n",
    "for x,y in zip(x_sen,y_sen):\n",
    "    a =  a + [['<START>'] + x + ['<PAD>'] * (max_len-len(x))]\n",
    "    b =  b + [['<START>']  + y + ['<PAD>'] * (max_len-len(y)) + ['<END>']] # 이거 제대로 되는지 확인하고 x,y 인풋들 다 idx로 바꾸자 180502 \n",
    "x_sen = a\n",
    "y_sen = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dic 만들기\n",
    "idx_to_ch = {}\n",
    "ch_to_idx = {}\n",
    "for idx, ch in enumerate(set(' '.join(sentences).split(' ') + ['<START>', '<END>', '<PAD>'])):\n",
    "    idx_to_ch[idx]= ch\n",
    "    ch_to_idx[ch]= idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=[]\n",
    "b=[]\n",
    "for x_words in x_sen:\n",
    "    t1=[]\n",
    "    for x_word in x_words:\n",
    "        t1.append(ch_to_idx[x_word])\n",
    "    a.append(t1)\n",
    "    \n",
    "for y_words in y_sen:\n",
    "    t1=[]\n",
    "    for y_word in y_words:\n",
    "        t1.append(ch_to_idx[y_word])\n",
    "    b.append(t1)\n",
    "x_sen=a\n",
    "y_sen=b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_dim = 200\n",
    "batch_size = len(sentences)\n",
    "n_class = len(idx_to_ch)\n",
    "n_stack = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 14)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_sen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.placeholder(dtype=tf.float32, shape=[batch_size,32,32,3]) # 이미지 데이터의 경우 shape은 [number, height, width, channels] 순이다\n",
    "x_sentences = tf.placeholder(shape=[batch_size, max_len+1], dtype=tf.int32)\n",
    "y_sentences = tf.placeholder(shape=[batch_size, max_len+2], dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = tf.one_hot(x_sentences, depth=n_class)\n",
    "y_train = tf.one_hot(y_sentences, depth=n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"First_Layer\") as scope: \n",
    "    w1 = tf.Variable(tf.random_normal(shape=[3,3,3,32], stddev=0.01), name = \"W1\") # shape !!!!!!!!!!\n",
    "    L1 = tf.nn.conv2d(input= x_image, filter= w1, strides=[1,1,1,1], padding='SAME', name=\"L1\")\n",
    "    \n",
    "    L1 = tf.nn.relu(L1)\n",
    "    L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1],  strides= [1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Second_Layer\") as scope:  \n",
    "    w2 = tf.Variable(tf.random_normal(shape=[3,3,32,64], stddev=0.01))\n",
    "    L2 = tf.nn.conv2d(input= L1, filter= w2, strides=[1,1,1,1], padding='SAME') \n",
    "    L2 = tf.nn.relu(L2)\n",
    "    L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1],  strides= [1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L2 = tf.reshape(tensor = L2, shape=[batch_size, 1, 8*8*64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(10, 1, 4096) dtype=float32>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# state_from_cnn 만들기 \n",
    "w_init = tf.get_variable(shape=[batch_size,8*8*64, n_class], name='w_init')\n",
    "b_init = tf.get_variable(shape=[n_class], name='b_init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_input = tf.add(tf.matmul(L2, w_init), b_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Add:0' shape=(10, 1, 63) dtype=float32>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_hy = tf.get_variable(shape=[hidden_dim, n_class], name='w_hy')\n",
    "b_hy = tf.get_variable(shape=[n_class], name='b_hy')\n",
    "weight = tf.ones(shape = [batch_size, max_len+2]) # 아니 seq_length 가 문장마다 다다른데 어떻게 해야대 ..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat:0' shape=(10, 15, 63) dtype=float32>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([image_input, x_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.LSTMCell(num_units= hidden_dim, state_is_tuple=True) for _ in range(n_stack)], state_is_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output, _state = tf.nn.dynamic_rnn(cell, inputs= tf.concat([image_input, x_train], axis=1), sequence_length=seq_len, dtype=tf.float32) # x_train은 onehot 변형된 상태임!!!\n",
    "output = tf.reshape(output, [-1,hidden_dim])\n",
    "output = tf.add(tf.matmul(output, w_hy), b_hy)\n",
    "output = tf.reshape(output, shape=[batch_size, max_len+2, n_class])\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits= output, targets=y_sentences, weights=weight) # taraget은 onehot 변환 전의 상태로! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ArgMax:0' shape=(10, 15) dtype=int64>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(output,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(loss=sequence_loss)\n",
    "prediction = tf.argmax(output, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ite = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window. window. window. an an an an an an an an window. window. jacket jacket\n",
      "<START> A woman is is talking to to to old old old old <END> <END>\n",
      "<START> A woman is talking to an old lady outside through window. <PAD> <PAD> <PAD>\n",
      "<START> A woman is talking to an old lady outside through window. <PAD> <PAD> <PAD>\n",
      "<START> A woman is talking to an old lady outside through window. <PAD> <PAD> <PAD>\n",
      "<START> A woman is talking to an old lady outside through window. <PAD> <PAD> <PAD>\n",
      "<START> A woman is talking to an old lady outside through window. <PAD> <PAD> <PAD>\n",
      "<START> A woman is talking to an old lady outside through window. <PAD> <PAD> <PAD>\n",
      "<START> A woman is talking to an old lady outside through window. <PAD> <PAD> <PAD>\n",
      "<START> A woman is talking to an old lady outside through window. <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(ite):\n",
    "    sess.run(train, feed_dict={x_sentences : x_sen, y_sentences : y_sen, x_image:images})\n",
    "    if i % 100 ==0 : \n",
    "        t = sess.run(prediction, feed_dict={x_sentences : x_sen, x_image:images})\n",
    "        print(\" \".join([idx_to_ch[tt] for tt in t[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> A woman is talking to an old lady outside through window. <PAD> <PAD> <PAD>\n"
     ]
    }
   ],
   "source": [
    "t = sess.run(prediction, feed_dict={x_sentences : x_sen, x_image:images})\n",
    "print(\" \".join([idx_to_ch[tt] for tt in t[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> A woman in red ski jacket is skiing. <PAD> <PAD> <PAD> <PAD> <PAD> "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x237bd8f51d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_idx=5\n",
    "\n",
    "test_x = [[-1]*(max_len+1)]*batch_size\n",
    "for i in range(max_len+1):  \n",
    "    t = sess.run(prediction, feed_dict={x_sentences : test_x, x_image:images}) # 여기서 새 이미지를 batch_size만큼 묶어서 넣으면됨 .\n",
    "    test_x[image_idx][i] = t[image_idx][i]\n",
    "    #print(test_x[image_idx]) # 이전단어로 하나씩 인풋을 업그레이드 해나가는 것을 확인할 수 있다.\n",
    "    print(idx_to_ch[t[image_idx][i]], end=' ')\n",
    "imshow(images[image_idx])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
