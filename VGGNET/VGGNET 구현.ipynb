{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFilter\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_dic = {\n",
    "    'bicycle' : 0,\n",
    "    'horse' : 1,\n",
    "    'ship' : 2,\n",
    "    'truck' : 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_set = {}\n",
    "resizing = (32, 32)\n",
    "\n",
    "for label in label_dic:\n",
    "    image_dir = os.getcwd() + '/' + label\n",
    "    labeled_image = []\n",
    "\n",
    "    os.walk(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_set = {}\n",
    "resizing = (32, 32)\n",
    "\n",
    "for label in label_dic:\n",
    "    image_dir = os.getcwd() + '/' + label\n",
    "    labeled_image = []\n",
    "\n",
    "    for path, dir, files in os.walk(image_dir):\n",
    "        for file in files:\n",
    "            image_dir = path + '/' + file\n",
    "            img = Image.open(image_dir)\n",
    "            img = img.resize(resizing)\n",
    "            if not img.format == \"RGB\": # 이미지의 포맷이 RGB가 아닐 경우, RGB로 convert 시킴\n",
    "                img = img.convert(\"RGB\")\n",
    "            labeled_image.append(np.array(img))\n",
    "    \n",
    "    image_set[label] = np.array(labeled_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_class_size = 200\n",
    "test_class_size = 20\n",
    "\n",
    "\n",
    "data_set = {\n",
    "    'train_image': np.empty(1),\n",
    "    'train_label': np.empty(1),\n",
    "    'test_image': np.empty(1),\n",
    "    'test_label': np.empty(1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_class_size = 200\n",
    "test_class_size = 20\n",
    "\n",
    "data_set = {\n",
    "    'train_image' : np.empty((1,resizing[0],resizing[1],3)),\n",
    "    'train_label' : np.empty(1),\n",
    "    'test_image' : np.empty((1,resizing[0],resizing[1],3)),\n",
    "    'test_label' : np.empty(1)\n",
    "}\n",
    "\n",
    "for label in image_set:\n",
    "    label_index = np.random.randint(len(image_set[label]), size=train_class_size + test_class_size)\n",
    "    \n",
    "    train_image = image_set[label][label_index[:train_class_size]]\n",
    "    test_image = image_set[label][label_index[train_class_size:train_class_size+test_class_size]]\n",
    "    train_label = np.repeat(label_dic[label], train_class_size)\n",
    "    test_label = np.repeat(label_dic[label], test_class_size)\n",
    "    \n",
    "    data_set['train_image'] = np.concatenate((data_set['train_image'], train_image), axis = 0)\n",
    "    data_set['test_image'] = np.concatenate((data_set['test_image'], test_image), axis = 0)\n",
    "    data_set['train_label'] = np.concatenate((data_set['train_label'], train_label), axis = 0)\n",
    "    data_set['test_label'] = np.concatenate((data_set['test_label'], test_label), axis = 0) # np.concatenate는 cbind, rbind 같은 기능\n",
    "\n",
    "data_set['train_image'] = data_set['train_image'][1:]\n",
    "data_set['train_label'] = data_set['train_label'][1:]\n",
    "data_set['test_image'] = data_set['test_image'][1:]\n",
    "data_set['test_label'] = data_set['test_label'][1:] # 처음에 넣어줬던 무의미한 값을 빼주는 단계 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 32, 32, 3), (80, 32, 32, 3))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set['train_image'].shape, data_set['test_image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800,), (80,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set['train_label'].shape, data_set['test_label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### VGG NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=[None,32, 32,3])\n",
    "y = tf.placeholder(dtype=tf.int32, shape=[None,1])\n",
    "y_one_hot = tf.one_hot(y, 4)\n",
    "y_one_hot = tf.reshape(y_one_hot, [-1, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w1 = tf.Variable(tf.random_normal(shape=[3,3,3,64], stddev=0.01))\n",
    "L1 = tf.nn.conv2d(filter=w1, input=x, strides=[1,1,1,1], padding=\"SAME\")\n",
    "L1 = tf.nn.relu(L1)\n",
    "w1_1 = tf.Variable(tf.random_normal(shape=[3,3,64,64], stddev=0.01))\n",
    "L1_1 = tf.nn.conv2d(filter=w1_1, input=L1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "L1_1 = tf.nn.relu(L1_1)\n",
    "\n",
    "L1_1 = tf.nn.max_pool(L1_1, strides=[1,2,2,1], ksize=[1,2,2,1], padding=\"SAME\") # ksize가모지 ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool:0' shape=(?, 16, 16, 64) dtype=float32>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2 = tf.Variable(tf.random_normal(shape=[3,3,64,128], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(filter=w2, input=L1_1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "L2 = tf.nn.relu(L2)\n",
    "\n",
    "w2_1 = tf.Variable(tf.random_normal(shape=[3,3,128,128], stddev=0.01))\n",
    "L2_2 = tf.nn.conv2d(filter=w2_1, input=L2, strides=[1,1,1,1], padding=\"SAME\")\n",
    "L2_2 = tf.nn.relu(L2_2)\n",
    "L2_2 = tf.nn.max_pool(L2_2, padding=\"SAME\", strides=[1,2,2,1], ksize=[1,2,2,1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w3 = tf.Variable(tf.random_normal(shape=[3,3,128,256], stddev=0.01))\n",
    "L3 = tf.nn.conv2d(filter=w3, input=L2_2, strides=[1,1,1,1], padding=\"SAME\")\n",
    "L3 = tf.nn.relu(L3)\n",
    "w4 = tf.Variable(tf.random_normal(shape=[3,3,256,256], stddev=0.01))\n",
    "L4 = tf.nn.conv2d(filter=w4, input=L3, strides=[1,1,1,1], padding=\"SAME\")\n",
    "L4 = tf.nn.relu(L4)\n",
    "w5 = tf.Variable(tf.random_normal(shape=[3,3,256,256], stddev=0.01))\n",
    "L5 = tf.nn.conv2d(filter=w5, input=L4, strides=[1,1,1,1], padding=\"SAME\")\n",
    "L5 = tf.nn.relu(L5)\n",
    "\n",
    "L5 = tf.nn.max_pool(L5, padding=\"SAME\", strides=[1,2,2,1], ksize=[1,2,2,1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_2:0' shape=(?, 4, 4, 256) dtype=float32>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w6 = tf.Variable(tf.random_normal(shape=[3,3,256,512], stddev=0.01))\n",
    "L6 = tf.nn.conv2d(filter=w6, input=L5, strides=[1,1,1,1], padding=\"SAME\")\n",
    "L6 = tf.nn.relu(L6)\n",
    "w7 = tf.Variable(tf.random_normal(shape=[3,3,512,512], stddev=0.01))\n",
    "L7 = tf.nn.conv2d(filter=w7, input=L6, strides=[1,1,1,1], padding=\"SAME\")\n",
    "L7 = tf.nn.relu(L7)\n",
    "\n",
    "L7 = tf.nn.max_pool(L7, padding=\"SAME\", strides=[1,2,2,1], ksize=[1,2,2,1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_3:0' shape=(?, 2, 2, 512) dtype=float32>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L7_flat = tf.reshape(L7, shape=[-1,2*2*512]) \n",
    "w8 = tf.Variable(tf.random_normal(shape=[2*2*512, 100], stddev=0.01))\n",
    "b1 = tf.Variable(tf.random_normal(shape = [100]))\n",
    "FC1 = tf.matmul(L7_flat, w8) +b1\n",
    "\n",
    "w9 = tf.Variable(tf.random_normal(shape=[100, 100], stddev=0.01))\n",
    "b2 = tf.Variable(tf.random_normal(shape = [100]))\n",
    "FC2 = tf.matmul(FC1, w9) +b2\n",
    "\n",
    "w10 = tf.Variable(tf.random_normal(shape=[100, 4], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal(shape = [4]))\n",
    "logits = tf.matmul(FC2, w10) +b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 20\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_one_hot))\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=lr, momentum=0.9)\n",
    "training_op = optimizer.minimize(loss)\n",
    "correct = tf.equal(tf.argmax(logits,1), tf.argmax(y_one_hot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = np.reshape(data_set['train_label'], newshape=[-1,1])\n",
    "test_y = np.reshape(data_set['test_label'], newshape=[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train accuracy: 0.3 Test accuracy: 0.25\n",
      "Epoch: 1 Train accuracy: 0.2 Test accuracy: 0.25\n",
      "Epoch: 2 Train accuracy: 0.4 Test accuracy: 0.25\n",
      "Epoch: 3 Train accuracy: 0.25 Test accuracy: 0.25\n",
      "Epoch: 4 Train accuracy: 0.25 Test accuracy: 0.25\n",
      "Epoch: 5 Train accuracy: 0.15 Test accuracy: 0.25\n",
      "Epoch: 6 Train accuracy: 0.35 Test accuracy: 0.25\n",
      "Epoch: 7 Train accuracy: 0.3 Test accuracy: 0.25\n",
      "Epoch: 8 Train accuracy: 0.25 Test accuracy: 0.25\n",
      "Epoch: 9 Train accuracy: 0.25 Test accuracy: 0.25\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(data_set['train_image'].shape[0]//batch_size):\n",
    "            index = np.random.randint(train_class_size*4 ,size = batch_size)\n",
    "            sess.run(training_op, feed_dict={x : data_set['train_image'][index], y : train_y[index]})\n",
    "            \n",
    "        acc_train = accuracy.eval(feed_dict={x : data_set['train_image'][index], y : train_y[index]})\n",
    "        acc_test = accuracy.eval(feed_dict={x : data_set['test_image'], y : test_y})\n",
    "        print(\"Epoch:\", epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
